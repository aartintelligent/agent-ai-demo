# ğŸ§  Agent AI Demo

DÃ©monstration dâ€™un agent IA custom en Rust
Ce projet est une dÃ©monstration technique visant Ã  mettre en valeur mes compÃ©tences en dÃ©veloppement dâ€™un agent conversationnel intelligent, conÃ§u sur mesure en Rust.

Il sâ€™agit dâ€™un agent autonome, capable de :

GÃ©rer son propre Ã©tat interne via une machine Ã  Ã©tats typÃ©e (ChatAgentStateMachine)

RÃ©agir dynamiquement Ã  des requÃªtes utilisateurs, en sÃ©lectionnant des outils spÃ©cialisÃ©s (ex: recherche arXiv)

IntÃ©grer des appels externes Ã  des services ou sources de donnÃ©es (API, scraping, etc.)

Structurer ses sorties de maniÃ¨re claire et naturelle

## Objectif

### Recherche dâ€™articles scientifiques via arXiv

Ce projet intÃ¨gre un composant permettant dâ€™interroger automatiquement la plateforme [arXiv.org](https://arxiv.org) afin
de rÃ©cupÃ©rer des articles scientifiques pertinents en rÃ©ponse Ã  une requÃªte utilisateur.

#### Fonctionnement

* Lorsquâ€™une requÃªte de type recherche scientifique est dÃ©tectÃ©e, le systÃ¨me construit dynamiquement une requÃªte HTTP
  vers lâ€™**API arXiv**.
* Le flux de rÃ©ponse, au format **Atom XML**, est parsÃ© et transformÃ© en une structure Rust typÃ©e (`ArxivResult`),
  contenant :

    * le titre de lâ€™article,
    * un rÃ©sumÃ© (abstract),
    * un lien vers la publication.

#### Exemple de scÃ©nario

> Utilisateur : *"Quels sont les derniers travaux sur les agents conversationnels multi-modaux ?"*

Lâ€™agent effectue alors une recherche sur arXiv avec le mot-clÃ© `"multi-modal conversational agents"` et retourne une
sÃ©lection dâ€™articles pertinents.

#### Format de rÃ©ponse

Le systÃ¨me retourne les rÃ©sultats sous forme synthÃ©tique, en langage naturel, avec un lien cliquable vers chaque
article, exemple : Titre, RÃ©sumÃ© et lien.

#### Remarques

* Seuls les 5 Ã  10 premiers rÃ©sultats sont retournÃ©s, filtrÃ©s par pertinence.
* Lâ€™API arXiv est publique et ne nÃ©cessite pas dâ€™authentification, mais respecte une limite de taux implicite (\~1
  req/s).
* Lâ€™intÃ©gration actuelle est focalisÃ©e sur la **catÃ©gorie IA (cs.AI)** mais peut Ãªtre Ã©tendue Ã  d'autres domaines (
  `stat.ML`, `cs.CL`, etc.).

## Execution

```text
=== Research Assistant State Machine Demo ===

ğŸ” Searching arXiv for 'multi-modal conversational agents'

Processing result 1...

ğŸ“ State: Processing Queue

ğŸ“ State: Processing

ğŸ¤– Assistant:

Le document intitulÃ© "DAG-Net: Double Attentive Graph Neural Network for Trajectory Forecasting" propose un modÃ¨le visant Ã  comprendre le comportement humain en matiÃ¨re de mouvement, essentiel pour des applications telles que les voitures autonomes ou les robots sociaux. Ce dÃ©fi est complexe en raison de la nature multi-modale du mouvement humain, oÃ¹ plusieurs trajectoires futures sont possibles Ã  partir des chemins historiques. En outre, les activitÃ©s humaines sont souvent orientÃ©es par des objectifs, comme atteindre des lieux spÃ©cifiques ou interagir avec l'environnement.

Pour rÃ©pondre Ã  ces enjeux, les auteurs prÃ©sentent un nouveau modÃ¨le gÃ©nÃ©ratif rÃ©current qui prend en compte les objectifs futurs des agents individuels ainsi que les interactions entre diffÃ©rents agents. Ce modÃ¨le utilise un rÃ©seau de neurones graphiques basÃ© sur une double attention pour recueillir des informations sur les influences mutuelles entre agents et intÃ©grer ces donnÃ©es avec les objectifs futurs. Ce modÃ¨le est suffisamment gÃ©nÃ©ral pour Ãªtre appliquÃ© Ã  divers scÃ©narios et atteint des rÃ©sultats de pointe tant dans les environnements urbains que dans des applications sportives. 

Pour plus de dÃ©tails, vous pouvez consulter le lien : [DAG-Net sur arXiv](http://arxiv.org/abs/2005.12661v2).

ğŸ“ State: Ready

Processing result 2...

ğŸ“ State: Processing Queue

ğŸ“ State: Processing

ğŸ¤– Assistant:

Le document intitulÃ© "Using Conversational Agents To Support Learning By Teaching" explore comment les agents conversationnels peuvent Ãªtre utilisÃ©s pour soutenir le paradigme "apprendre en enseignant". Traditionnellement, les agents pÃ©dagogiques sont conÃ§us pour jouer le rÃ´le d'enseignants humains en donnant des instructions aux Ã©lÃ¨ves. Cependant, cette Ã©tude se concentre sur l'utilisation d'agents conversationnels qui reÃ§oivent des instructions de la part des Ã©tudiants.

Les auteurs prÃ©sentent une application Ã©ducative nommÃ©e Curiosity Notebook, qui exploite les interventions conversationnelles pour faciliter l'apprentissage des Ã©tudiants. La reconnaissance de ces interventions peut non seulement aider Ã  engager les Ã©tudiants lors des interactions d'apprentissage, mais aussi offrir une comprÃ©hension plus approfondie des dÃ©fis liÃ©s Ã  la conception d'agents conversationnels Ã  des fins Ã©ducatives.

Pour plus d'informations, vous pouvez consulter le lien : [Using Conversational Agents To Support Learning By Teaching sur arXiv](http://arxiv.org/abs/1909.13443v1).

ğŸ“ State: Ready

Processing result 3...

ğŸ“ State: Processing Queue

ğŸ“ State: Processing

ğŸ¤– Assistant:

Le document intitulÃ© "Designing Style Matching Conversational Agents" aborde les avancÃ©es en intelligence artificielle qui permettent de crÃ©er des interfaces conversationnelles susceptibles de transformer radicalement les interactions humaines avec les machines. MalgrÃ© ces progrÃ¨s, des lacunes subsistent dans la capacitÃ© des agents Ã  interagir de maniÃ¨re naturelle, notamment parce qu'ils adoptent souvent un comportement monotone et ne s'adaptent pas Ã  leur interlocuteur.

Les auteurs prÃ©sentent deux agents conversationnels de bout-en-bout : le premier est un agent vocal capable de mener des dialogues naturels et de s'aligner sur le style de conversation de l'interlocuteur, tandis que le second, un agent conversationnel incarnÃ© (ECA), reconnaÃ®t le comportement humain lors de conversations ouvertes et ajuste automatiquement ses rÃ©ponses en fonction du style visuel et conversationnel de l'autre participant. L'ECA utilise des entrÃ©es multimodales pour gÃ©nÃ©rer des rÃ©ponses vocales et faciales riches et perceptuellement valables, telles que le synchronisme labial et les expressions faciales.

Ã€ partir des rÃ©sultats empiriques d'Ã©tudes utilisateurs, les auteurs soulignent plusieurs dÃ©fis majeurs dans la construction de tels systÃ¨mes et proposent des directives de conception pour les interactions de dialogue multi-tours en utilisant l'adaptation de style dans la recherche future.

Pour plus de dÃ©tails, vous pouvez consulter le lien : [Designing Style Matching Conversational Agents sur arXiv](http://arxiv.org/abs/1910.07514v1).

ğŸ“ State: Ready

Processing result 4...

ğŸ“ State: Processing Queue

ğŸ“ State: Processing

ğŸ¤– Assistant:

Le document intitulÃ© "What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents" aborde les limites des agents conversationnels, qui promettent une interaction conversationnelle mais Ã©chouent souvent Ã  livrer cette expÃ©rience. Les tentatives de crÃ©ation de ces agents se basent souvent sur des rÃ¨gles fonctionnelles issues de la communication humaine, sans prendre en compte les caractÃ©ristiques clÃ©s que doit contenir une vÃ©ritable conversation.

L'objectif de l'Ã©tude est de comprendre ce que les gens apprÃ©cient dans une conversation et comment cela devrait se reflÃ©ter dans la conception des agents. Les rÃ©sultats d'entretiens semi-structurÃ©s montrent que les participants Ã©tablissent une distinction claire entre les rÃ´les sociaux et fonctionnels des conversations, soulignant l'importance des dynamiques de lien et de confiance Ã  long terme, ainsi que l'importance du contexte et de la phase de la relation dans le type de conversations qu'ils entretiennent.

Les participants remettent Ã©galement en question la nÃ©cessitÃ© d'un lien et d'un terrain d'entente dans la communication avec les agents, se tournant plutÃ´t vers des dÃ©finitions plus utilitaires des qualitÃ©s conversationnelles. Sur la base de ces rÃ©sultats, les auteurs discutent des dÃ©fis majeurs liÃ©s Ã  la conception d'agents conversationnels, notamment la nÃ©cessitÃ© de redÃ©finir les paramÃ¨tres de conception pour les interactions avec ces agents.

Pour plus de dÃ©tails, vous pouvez consulter le lien : [What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents sur arXiv](http://arxiv.org/abs/1901.06525v1).

ğŸ“ State: Ready

Processing result 5...

ğŸ“ State: Processing Queue

ğŸ“ State: Processing

ğŸ¤– Assistant:

Le document intitulÃ© "Memory Sandbox: Transparent and Interactive Memory Management for Conversational Agents" traite de la gestion de la mÃ©moire dans les agents conversationnels alimentÃ©s par des modÃ¨les de langage de grande taille (LLM), comme chatGPT. Pour offrir des rÃ©ponses contextuellement pertinentes, ces agents doivent se souvenir d'informations clÃ©s d'une conversation en cours. Cependant, leur mÃ©moire est limitÃ©e et ils peuvent Ãªtre distraits par des Ã©lÃ©ments non pertinents de la conversation.

Actuellement, les utilisateurs n'ont pas de moyens efficaces pour visualiser et contrÃ´ler ce que l'agent se souvient, ce qui entraÃ®ne une mauvaise comprÃ©hension de la dynamique de la conversation et des interruptions dans l'interaction. Les auteurs introduisent "Memory Sandbox", un systÃ¨me interactif qui permet aux utilisateurs de gÃ©rer la mÃ©moire conversationnelle des agents alimentÃ©s par LLM. En traitant les souvenirs comme des objets de donnÃ©es pouvant Ãªtre visualisÃ©s, manipulÃ©s, enregistrÃ©s, rÃ©sumÃ©s et partagÃ©s Ã  travers les conversations, Memory Sandbox offre des fonctionnalitÃ©s d'interaction pour que les utilisateurs puissent guider la perception de la conversation par l'agent.

Pour plus de dÃ©tails, vous pouvez consulter le lien : [Memory Sandbox sur arXiv](http://arxiv.org/abs/2308.01542v1).

ğŸ“ State: Ready

=== Demo Complete ===
```
